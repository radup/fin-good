"""initial_tables

Revision ID: d7a37370ef38
Revises: 
Create Date: 2025-08-18 13:58:45.611865+00:00

FINANCIAL SAFETY NOTICE:
This migration affects financial data. Ensure proper backup and testing procedures
are followed before applying to production. All changes must be reversible.

ROLLBACK STRATEGY:
- Test rollback procedures in staging environment
- Verify data integrity after rollback
- Document any manual steps required for rollback

"""
from typing import Sequence, Union
import logging

from alembic import op
import sqlalchemy as sa
from sqlalchemy.exc import SQLAlchemyError, OperationalError


# revision identifiers, used by Alembic.
revision: str = 'd7a37370ef38'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

# Configure logging for this migration
logger = logging.getLogger(__name__)


def validate_data_integrity() -> bool:
    """
    Validate financial data integrity before and after migration.
    This function should be customized for each migration's specific requirements.
    """
    try:
        # Add specific validation logic here
        # Example: Check for orphaned records, constraint violations, etc.
        logger.info("Data integrity validation passed")
        return True
    except Exception as e:
        logger.error(f"Data integrity validation failed: {e}")
        return False


def upgrade() -> None:
    """Apply the migration changes."""
    logger.info(f"Starting migration upgrade: initial_tables")
    
    try:
        # Validate data integrity before migration
        if not validate_data_integrity():
            raise RuntimeError("Pre-migration data integrity check failed")
        
        # ### commands auto generated by Alembic - please adjust! ###
        op.create_table('revoked_tokens',
            sa.Column('id', sa.Integer(), nullable=False),
            sa.Column('jti', sa.String(length=255), nullable=False),
            sa.Column('token_hash', sa.String(length=255), nullable=False),
            sa.Column('user_id', sa.Integer(), nullable=False),
            sa.Column('revoked_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
            sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
            sa.Column('revocation_reason', sa.String(length=100), nullable=True),
            sa.Column('client_ip', sa.String(length=45), nullable=True),
            sa.Column('user_agent', sa.Text(), nullable=True),
            sa.PrimaryKeyConstraint('id')
        )
        with op.batch_alter_table('revoked_tokens', schema=None) as batch_op:
            batch_op.create_index('idx_revoked_tokens_audit', ['user_id', 'revoked_at'], unique=False)
            batch_op.create_index('idx_revoked_tokens_cleanup', ['expires_at'], unique=False)
            batch_op.create_index('idx_revoked_tokens_lookup', ['token_hash', 'expires_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_revoked_tokens_id'), ['id'], unique=False)
            batch_op.create_index(batch_op.f('ix_revoked_tokens_jti'), ['jti'], unique=True)
            batch_op.create_index(batch_op.f('ix_revoked_tokens_token_hash'), ['token_hash'], unique=False)
            batch_op.create_index(batch_op.f('ix_revoked_tokens_user_id'), ['user_id'], unique=False)

        op.create_table('password_reset_tokens',
            sa.Column('id', sa.Integer(), nullable=False),
            sa.Column('user_id', sa.Integer(), nullable=False),
            sa.Column('token_hash', sa.String(length=255), nullable=False),
            sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
            sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
            sa.Column('used_at', sa.DateTime(timezone=True), nullable=True),
            sa.Column('is_used', sa.Boolean(), nullable=False),
            sa.Column('created_ip', sa.String(length=45), nullable=True),
            sa.Column('used_ip', sa.String(length=45), nullable=True),
            sa.Column('user_agent', sa.Text(), nullable=True),
            sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
            sa.PrimaryKeyConstraint('id')
        )
        with op.batch_alter_table('password_reset_tokens', schema=None) as batch_op:
            batch_op.create_index('idx_reset_tokens_cleanup', ['expires_at'], unique=False)
            batch_op.create_index('idx_reset_tokens_lookup', ['token_hash', 'expires_at', 'is_used'], unique=False)
            batch_op.create_index('idx_reset_tokens_user_active', ['user_id', 'is_used', 'expires_at'], unique=False)
            batch_op.create_index(batch_op.f('ix_password_reset_tokens_id'), ['id'], unique=False)
            batch_op.create_index(batch_op.f('ix_password_reset_tokens_token_hash'), ['token_hash'], unique=True)
            batch_op.create_index(batch_op.f('ix_password_reset_tokens_user_id'), ['user_id'], unique=False)

    # ### end Alembic commands ###
        
        # Validate data integrity after migration
        if not validate_data_integrity():
            raise RuntimeError("Post-migration data integrity check failed")
        
        logger.info(f"Migration upgrade completed successfully: initial_tables")
        
    except (SQLAlchemyError, OperationalError) as e:
        logger.error(f"Database error in migration upgrade: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in migration upgrade: {e}")
        raise


def downgrade() -> None:
    """Rollback the migration changes."""
    logger.info(f"Starting migration downgrade: initial_tables")
    
    try:
        # Validate data integrity before rollback
        if not validate_data_integrity():
            raise RuntimeError("Pre-rollback data integrity check failed")
        
        # ### commands auto generated by Alembic - please adjust! ###
        with op.batch_alter_table('password_reset_tokens', schema=None) as batch_op:
            batch_op.drop_index(batch_op.f('ix_password_reset_tokens_user_id'))
            batch_op.drop_index(batch_op.f('ix_password_reset_tokens_token_hash'))
            batch_op.drop_index(batch_op.f('ix_password_reset_tokens_id'))
            batch_op.drop_index('idx_reset_tokens_user_active')
            batch_op.drop_index('idx_reset_tokens_lookup')
            batch_op.drop_index('idx_reset_tokens_cleanup')

        op.drop_table('password_reset_tokens')
        with op.batch_alter_table('revoked_tokens', schema=None) as batch_op:
            batch_op.drop_index(batch_op.f('ix_revoked_tokens_user_id'))
            batch_op.drop_index(batch_op.f('ix_revoked_tokens_token_hash'))
            batch_op.drop_index(batch_op.f('ix_revoked_tokens_jti'))
            batch_op.drop_index(batch_op.f('ix_revoked_tokens_id'))
            batch_op.drop_index('idx_revoked_tokens_lookup')
            batch_op.drop_index('idx_revoked_tokens_cleanup')
            batch_op.drop_index('idx_revoked_tokens_audit')

        op.drop_table('revoked_tokens')
        # ### end Alembic commands ###
        
        # Validate data integrity after rollback
        if not validate_data_integrity():
            raise RuntimeError("Post-rollback data integrity check failed")
        
        logger.info(f"Migration downgrade completed successfully: initial_tables")
        
    except (SQLAlchemyError, OperationalError) as e:
        logger.error(f"Database error in migration downgrade: {e}")
        raise
    except Exception as e:
        logger.error(f"Unexpected error in migration downgrade: {e}")
        raise
